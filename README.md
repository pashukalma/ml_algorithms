### Machine Learning Algorithm Implementations

This repository details the theory and implementation of core machine learning algorithms, with a strong focus on Bayesian methods and probabilistic modeling. A comprehensive view of **fundamental and advanced machine learning algorithms**, spanning supervised learning, unsupervised learning, Bayesian statistics, and specific financial and optimization applications.


-  **Fundamentals of Learning** (#classTypes.ipynb, #linearReg.ipynb, #logisticReg.ipynb): Covers the basic machine learning workflow, detailing classification (Perceptron), linear regression (including Bayesian Linear Regression and Ridge regression), and performance metrics like confusion matrices, ROC/AUC, and F1 scores.
- **Bayesian Inference** and Sampling (#mcmc.ipynb, #variationalInference.ipynb): Explores advanced probabilistic modeling.
- **MCMC**: Focuses on Markov Chain Monte Carlo methodology for sampling high-dimensional posterior distributions when analytical solutions are intractable.
- **Variational Inference (VI)**: Approaches inference as an optimization problem, utilizing KL Divergence and the Evidence Lower Bound (ELBO).
- **Unsupervised Learning** (#unsupervised.ipynb): Discusses pattern recognition and data representation through techniques such as Dirichlet Process K-means (a Bayesian nonparametric extension), Gaussian Mixture Models (GMMs) with EM algorithms, and dimensionality reduction (PCA, t-SNE).
- **Applications (#samplingMethods.ipynb)**: Demonstrates real-world uses of these algorithms, including Hidden Markov Models (HMMs) with the Viterbi algorithm, the PageRank algorithm, and strategies for Imbalanced Learning (e.g., SMOTE, Tomek links). It also touches on computational finance through Monte Carlo simulations like Binomial Tree models for stock pricing.
